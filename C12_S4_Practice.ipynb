{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Text Representation and Rule-based Matching**\n"
      ],
      "metadata": {
        "id": "zkE5XdWREVwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practice Solution**"
      ],
      "metadata": {
        "id": "mYHc_GbbEZG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector Representation of Text Data**\n",
        "\n",
        "Vector Representation of Text Data\n",
        "\n",
        "Consider the following texts to use in this practice session:\n",
        "\n",
        "1. I prefer the morning flight through Denmark.\n",
        "\n",
        "2. The infrastructure of our school is wonderful.\n",
        "\n",
        "3. Review 1: This movie is very scary and long. Review 2: This movie is not scary and is slow. Review 3: This movie is spooky and good.\n",
        "\n",
        "4. Do not put rotten mangoes and sweet oranges together."
      ],
      "metadata": {
        "id": "iGqLbwGeHoMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the spaCy library, which is a popular NLP library.\n",
        "import spacy\n",
        "\n",
        "# Import the collections library, which provides a variety of data structures, such as dictionaries and lists.\n",
        "import collections\n",
        "\n",
        "# Import the dictionary objects Dict, List, and Tuple, which are commonly used data structures in Python.\n",
        "from typing import Dict,List,Tuple"
      ],
      "metadata": {
        "id": "aZKwp77aH6Rm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1**\n",
        "\n",
        "Represent text 3 in vector form using BOW. Provide the following for the words 'review and 'scary':\n",
        "\n",
        "a) Bow vector representation\n",
        "\n",
        "b) Dictionary values"
      ],
      "metadata": {
        "id": "yamHa20xHpso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Converts a text to a bag-of-words (BOW) representation.\n",
        "\n",
        "  words: A list of strings representing the words in the text.\n",
        "    dictionary: A dictionary mapping words to integers.\n",
        "\n",
        "  Returns:\n",
        "    A list of tuples, where each tuple contains a word ID and its frequency.\"\"\"\n",
        "\n",
        "\n",
        "def text2bow(words: List[str],dictinory: Dict[str,int]) -> List[Tuple[int,int]]:\n",
        "    word_frequences = collections.defaultdict(int)\n",
        "\n",
        "    for word in words:\n",
        "        if word not in dictinory:                      # check condition\n",
        "            dictinory[word]= len(dictinory)            # each word index and index location\n",
        "\n",
        "        word_frequences[dictinory[word]] +=1\n",
        "\n",
        "    return list(word_frequences.items())               # return word frequency\n",
        "sample_text ='Review 1: This movie is very scary and long. Review 2: This movie is not scary and is slow. Review 3: This movie is spooky and good.'\n",
        "dictionary = {}\n",
        "print(text2bow(sample_text.split(),dictionary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSZ9OBbtIWlT",
        "outputId": "afd250ea-77fb-4e6c-f1a7-e83b5fb83557"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 3), (1, 1), (2, 3), (3, 3), (4, 4), (5, 1), (6, 2), (7, 3), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input text: \\n{}\".format(sample_text))\n",
        "\n",
        "print(\"\\nDictionary: \\n{}\".format(dictionary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuOOISJfJPmO",
        "outputId": "5196eb1c-1bfc-4052-bdb3-ed31c7fd1d4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text: \n",
            "Review 1: This movie is very scary and long. Review 2: This movie is not scary and is slow. Review 3: This movie is spooky and good.\n",
            "\n",
            "Dictionary: \n",
            "{'Review': 0, '1:': 1, 'This': 2, 'movie': 3, 'is': 4, 'very': 5, 'scary': 6, 'and': 7, 'long.': 8, '2:': 9, 'not': 10, 'slow.': 11, '3:': 12, 'spooky': 13, 'good.': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2**\n",
        "\n",
        "For the text, \"Hey, Siri! Hey Siri!\", how will you define pattern and implement token-based matching so you can obtain the following outcomes:\n",
        "\n",
        "a) Hey Siri\n",
        "\n",
        "b) Hey, Siri\n",
        "\n",
        "Think about patterns to define."
      ],
      "metadata": {
        "id": "yqux2gvzJE9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Matcher class from the spaCy library.\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy English language model.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a Matcher object.\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern to match the word\n",
        "pattern = [{\"LOWER\":'hey'},{'LOWER':'siri'}]\n",
        "\n",
        "# Add the pattern to the Matcher object with the ID \"Hey siri\".\n",
        "matcher.add(\"Hey siri\",[pattern])\n",
        "\n",
        "# Process the text using the spaCy language model.\n",
        "doc = nlp(\"Hey siri\")\n",
        "\n",
        "# Find all matches of the \"battlefield\" pattern in the text.\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches and print the text of each match.\n",
        "for match_id,start,end in matches:\n",
        "    # Get the string ID of the matched pattern.\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "\n",
        "    # Get the span of the matched text.\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # Print the text of the matched span.\n",
        "    print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH98blLZJvYt",
        "outputId": "844f7f76-9312-418d-c7b0-e4c9e465aac0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey siri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Matcher class from the spaCy library.\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy English language model.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a Matcher object.\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern to match the word\n",
        "pattern = [{\"LOWER\":'hey'},{\"IS_PUNCT\":True},{'LOWER':'siri'}]\n",
        "\n",
        "# Add the pattern to the Matcher object with the ID \"Hey siri\".\n",
        "matcher.add(\"Hey siri\",[pattern])\n",
        "\n",
        "# Process the text using the spaCy language model.\n",
        "doc = nlp(\"Hey, siri\")\n",
        "\n",
        "# Find all matches of the \"battlefield\" pattern in the text.\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches and print the text of each match.\n",
        "for match_id,start,end in matches:\n",
        "    # Get the string ID of the matched pattern.\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "\n",
        "    # Get the span of the matched text.\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # Print the text of the matched span.\n",
        "    print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4zmFQvKtuM",
        "outputId": "289b166e-2b55-4b50-b279-ae610ab00b62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey, siri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3**\n",
        "\n",
        "Do the tokens 'apple', 'orange', 'pikkstn', and 'German' have a vector representation in spaCy?\n",
        "\n",
        "Are they part of the pipeline's vocabulary in spacy oout-of- vocabulary?"
      ],
      "metadata": {
        "id": "EZIcoGjqH2Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Load the text into a spaCy Doc object.\n",
        "doc = nlp('apple orange pikkstn German')\n",
        "\n",
        "# Iterate over the tokens in the Doc object.\n",
        "for token in doc:\n",
        "    # Print the vector length of the token.\n",
        "    print('Vector Length:\\n',token.vector.shape)\n",
        "\n",
        "    # Print the vector representation of the token.\n",
        "    print('Word Vector Representation\\n',token.vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAQs0xXXLGs7",
        "outputId": "1d79403e-f81f-4dc4-fe91-9bf513976869"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Length:\n",
            " (96,)\n",
            "Word Vector Representation\n",
            " [-0.01291151 -0.63742214  0.6336341   0.7220289  -0.7089878  -0.2020278\n",
            " -0.21471749  1.7504792  -0.43238533 -0.75817096  1.8110483  -0.8448776\n",
            " -0.8092954  -0.60360026 -0.15348431  0.30619383 -0.9539893  -0.79956675\n",
            " -0.7785482  -0.8693065   0.21894354 -0.06897593  0.8038384   0.17259844\n",
            "  0.2581646   0.7076305   0.8857086   0.782564   -0.4451243   1.1322079\n",
            " -0.69896    -1.0962689   0.1928064   1.0511543  -0.6390506   0.26279163\n",
            "  1.7593797  -0.8621046   0.47793993  1.5560223  -0.92148495  1.457032\n",
            " -0.28774732  1.1776068  -0.6398139  -0.15469822  0.64170146  0.6397705\n",
            "  0.10651273 -0.5398765  -0.13111869 -1.6336241   0.9770989  -0.49307543\n",
            " -0.4739711  -0.433877   -0.22383378 -0.52839124  0.8471283  -0.24316812\n",
            " -1.392698    0.22927427 -0.29445207 -1.8478808  -0.7132102  -1.077588\n",
            " -0.26076427  0.51486564 -0.5803723  -0.91216826  0.24041569  0.5029696\n",
            "  0.4219088  -1.6083198  -0.07817796 -0.09576415  0.7770756  -0.04122347\n",
            "  0.6525791  -0.39792585  0.95907086 -0.16041932 -0.02049139 -1.1042901\n",
            " -0.09630179  0.4258653   0.14272809 -0.38179088 -0.7186223   0.6918746\n",
            " -0.37465477 -0.33817604  0.39940822  1.5588735  -0.6269769   0.10933062]\n",
            "Vector Length:\n",
            " (96,)\n",
            "Word Vector Representation\n",
            " [-0.48219478 -0.8879161   0.77188116 -0.09212857 -0.872227   -0.06087497\n",
            " -0.19773766  0.60087913  0.10527319 -0.521292    1.2793094   1.4865795\n",
            " -0.5602882  -0.68352735 -0.37648737  1.1974629  -0.65102154 -0.6749157\n",
            "  0.32830942 -0.07141492 -1.4182062   0.8189477  -0.7697373   0.13235147\n",
            "  0.68783486  0.14184943 -0.67017674  0.23376575 -0.48190784  1.1027646\n",
            " -0.43941343  0.01438388  0.3971234  -0.30096328 -0.48361817 -1.1059235\n",
            "  1.0644592   0.23570469  0.3536337  -1.7508998  -1.423107    0.7466299\n",
            " -0.92643535  0.13952743 -0.79238456  0.04731327  0.25721854  0.79803824\n",
            "  0.10066423  0.9858154  -1.1452986  -1.1978736   0.875546   -0.5886304\n",
            " -0.9412149  -0.8002951   0.93735677  0.10557401 -0.10572121 -0.18317658\n",
            " -1.0777463   1.2808043   0.08866367 -1.2707585  -1.0514246  -1.0393574\n",
            "  0.6482193   0.24688613  0.8412553  -0.04344732  0.9765717   1.5862397\n",
            "  0.7634014  -1.1051475   0.5845053   0.98328364 -0.83437675 -0.71610576\n",
            " -0.26160118 -0.25987047  0.52913356 -0.2520613  -1.7734828   0.19672889\n",
            " -1.1328119  -0.04406126 -0.18094997 -0.1844796  -0.87994385  1.2617023\n",
            " -0.74869466  0.43441767  1.5414302   0.7893902   0.11296847  0.5242842 ]\n",
            "Vector Length:\n",
            " (96,)\n",
            "Word Vector Representation\n",
            " [-0.72919613 -0.93858826  0.7890328   0.36545914 -0.45382163  0.19520926\n",
            "  0.42715502 -1.1640995   0.5606207  -1.0604131   1.3048911   1.0543224\n",
            " -0.99581563 -0.84921587 -1.1542796   0.17798582  0.36108023 -0.77407324\n",
            " -0.00446703 -0.01108103 -1.1228962   0.29787078 -1.8227218   0.68027556\n",
            "  0.08032517 -0.06465513  0.29591528  0.31131732 -0.5400094   0.27139106\n",
            " -0.37554833  0.87944806 -0.82009345  1.1500953  -0.18961984 -0.8219536\n",
            "  0.98609877 -0.4336438   0.01724015 -0.1533106  -1.6640887   0.9466558\n",
            " -1.10999     0.13889873 -0.23361269 -0.60636514 -0.732776    0.23582795\n",
            "  0.22540379  0.3724686  -0.12571344 -0.80252564  0.29503345  0.15230483\n",
            " -0.7438605  -0.22805548  0.80206025  0.5381145  -0.60066617  0.11447279\n",
            " -0.7500378  -0.38932443 -0.39014074 -0.8870872  -0.11783104 -0.5256261\n",
            " -0.21282873  1.7759534   0.1530866   2.2659054   1.6508703   0.9642472\n",
            "  0.9094777  -1.6882036   0.09743783  0.34422058  0.1035035  -0.11929873\n",
            " -0.19305742 -0.13666776 -0.36951676 -0.7549172   0.95351124  0.2709204\n",
            " -0.95452034  0.03104326  0.18716896  0.2521941  -0.69262433  1.7984687\n",
            "  0.45977017  0.5054407   0.9179981   0.46033585 -0.05572583 -0.07003435]\n",
            "Vector Length:\n",
            " (96,)\n",
            "Word Vector Representation\n",
            " [-1.01247287e+00 -8.71406555e-01 -1.13163638e+00  4.53890562e-02\n",
            "  8.36671948e-01 -5.10308146e-02 -2.93771863e-01  6.07491970e-01\n",
            "  2.35986471e-01 -5.18576503e-01  2.57586122e-01 -4.50986475e-01\n",
            "  3.46603692e-01  8.40262353e-01 -1.12680268e+00  3.23443949e-01\n",
            " -4.81796205e-01 -2.27388591e-01  4.97695446e-01  5.93989611e-01\n",
            "  6.56840801e-02  1.39822766e-01 -2.34026074e+00  4.96065438e-01\n",
            " -1.21557820e+00 -3.55896831e-01  1.37245178e+00  3.63409251e-01\n",
            " -3.57755989e-01  1.21780932e-01  2.26828247e-01  3.54993939e-02\n",
            " -1.45519763e-01  7.29695857e-01 -9.28744853e-01 -6.98245049e-01\n",
            "  7.28879333e-01  1.67400670e+00  1.58425868e-01 -7.07785130e-01\n",
            " -7.85632014e-01  5.13735712e-01 -8.69293571e-01 -7.36907840e-01\n",
            "  2.02924132e-01  1.60426825e-01 -2.26010188e-01 -1.24067640e+00\n",
            "  8.42003673e-02  2.74294019e-01  1.69777721e-01  8.76462102e-01\n",
            "  1.17153324e-01 -4.59485561e-01 -2.42060423e-03  1.23875213e+00\n",
            "  5.18011600e-02  4.93470311e-01  2.91320771e-01  2.49805272e-01\n",
            "  1.53806239e-01 -2.13347816e+00 -5.89362860e-01  6.45250976e-02\n",
            "  8.77180696e-03 -1.13070339e-01  1.39914215e+00  1.20535418e-01\n",
            " -2.27618024e-01 -8.82800758e-01  3.79744977e-01  7.23721266e-01\n",
            " -5.54815054e-01 -5.04451096e-01 -2.72659093e-01 -4.54761416e-01\n",
            " -9.03766453e-01  3.27999026e-01 -7.35947430e-01 -6.10857010e-01\n",
            "  5.83473206e-01 -1.68083012e-01 -6.96939230e-02 -1.07245609e-01\n",
            " -1.27255940e+00  1.45942748e+00  3.90473664e-01  5.56055248e-01\n",
            " -5.28663218e-01  5.21860838e-01 -8.23909283e-01  5.38776934e-01\n",
            "  2.89312267e+00  9.73923802e-02 -2.61319637e-01  5.15976429e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 4**\n",
        "\n",
        "For sentence 4, the phrases 'rotten mangoes' and 'sweet oranges should be matched using defined patterns ['ROTTEN mangoes', 'sweet oranges'].\n",
        "\n",
        "How will you set the attributes to achieve this?\n",
        "\n",
        "Sentence 4:\n",
        "\n",
        "\"Do not put rotten mangoes and sweet oranges together.\""
      ],
      "metadata": {
        "id": "GlkOMdEnLk90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Create a new PhraseMatcher object with case-insensitive matching.\n",
        "matcher = PhraseMatcher(nlp.vocab,attr='LOWER')\n",
        "\n",
        "# Create a list of phrases to match.\n",
        "terms = [\"ROTTEN mangoes\",\"sweet oranges\"]\n",
        "\n",
        "# Create a list of spaCy Doc objects from the list of phrases.\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "\n",
        "# Add the patterns to the PhraseMatcher object\n",
        "matcher.add(\"Fruits\",patterns)\n",
        "\n",
        "# Load the text to search into a spaCy Doc object.\n",
        "doc = nlp(\"Do not put rotten mangoes and sweet oranges together\")\n",
        "\n",
        "# Iterate over the matches found by the PhraseMatcher object.\n",
        "for match_id,start,end in matcher(doc):\n",
        "    # Print the matched text, along with a message indicating that the match was based on the lowercase token text.\n",
        "    print(\"Matched based on lowercase token text: \",doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzxFxTKZLty_",
        "outputId": "7f6adf1e-8782-4fb3-b595-130b747ddfd0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched based on lowercase token text:  rotten mangoes\n",
            "Matched based on lowercase token text:  sweet oranges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 5**\n",
        "\n",
        "Represent sentence 1 in the vector form using word vector representation.\n",
        "\n",
        "What is the total length of output vectors?\n",
        "\n",
        "Sentence 1:\n",
        "\n",
        "\"I prefer the morning flight through Denmark.\""
      ],
      "metadata": {
        "id": "M6GejXX1MmaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Load the text into a spaCy Doc object.\n",
        "doc = nlp(\"I prefer the morning fight through Denmark\")\n",
        "\n",
        "# Iterate over the tokens in the Doc object.\n",
        "for token in doc:\n",
        "    # Print the vector length of the token.\n",
        "    print(\"Vector length: \\n\",token.vector.shape)\n",
        "\n",
        "    # Print the vector representation of the token.\n",
        "    print(\"Word Vector Representation:\\n\",token.vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hRU62fdNG-2",
        "outputId": "786656dc-74cc-4bdf-daf6-6546ecb1c1fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [-0.9435841  -0.13761951 -0.41831952 -0.15897208 -0.4302298  -0.04438317\n",
            "  2.3614748   0.6231054   0.0122031  -0.79678786  2.2164228   1.634094\n",
            " -0.46185458  0.47664887 -1.5722715  -0.852956    0.7579042   1.0350271\n",
            " -0.91913295 -0.5994303  -0.90215635  0.22339064  0.22972403 -1.2096164\n",
            " -0.62598217 -0.50422657 -0.544212   -0.20867735 -1.2677568   0.25655213\n",
            " -0.12779951 -0.6996877  -0.82510996 -0.14156663 -0.42306674 -0.6998179\n",
            " -0.99681437 -0.4949299  -1.0885243   1.7996302  -0.9437039   0.33264816\n",
            "  0.03097375  1.1109407  -0.7527068  -0.53995335  0.8292919   3.7861528\n",
            " -0.08327061 -0.09838206 -1.1750913  -1.1477796   1.4207778  -1.2538137\n",
            "  0.56365967 -1.1316081   0.8606243  -0.9959679   0.16899098  1.0195899\n",
            "  1.4902151   0.12664063  0.5253415  -0.46430543  1.2312306   0.4858403\n",
            " -0.897334   -0.46871835 -1.1867027  -1.9095289   0.29641783 -0.31166956\n",
            "  1.0440685  -0.06307149 -1.1778319   0.52600086  1.2667065  -0.03227267\n",
            "  0.7472606   0.41688865 -1.405614   -0.96524596 -0.3139522   1.0063453\n",
            "  0.7510737   0.522592   -0.30218515  0.22849771  1.0321672  -0.04141968\n",
            "  1.5220734   0.5300121   1.0661025  -0.03359783 -0.28075555  0.6141777 ]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [-0.43908107 -0.46959734 -0.43020415 -0.07686606  1.3814722   0.07770494\n",
            " -0.11572167 -0.71886307 -0.01842189  0.07028744 -1.3842779  -0.29305208\n",
            " -0.57826674 -0.7245061   0.6691074  -0.17112814 -0.72851694 -1.4404652\n",
            " -1.5573331   0.09056683 -0.01049712 -0.29841292 -0.5023741   0.21571912\n",
            " -0.03532644 -0.8511338  -1.3917989   0.9816856  -0.13847259 -1.3228017\n",
            "  0.6910313   1.6609281  -0.08930665  0.046764   -0.8261384  -0.33957034\n",
            " -0.6380319   0.00337078  0.6460083  -0.8586641   1.861853    0.04298265\n",
            " -0.64312506 -0.11827451  0.5807551   0.11136986  1.2834818  -0.80179024\n",
            "  0.25335965 -0.33904213 -0.77207476  0.50671554 -0.8883302  -0.35959944\n",
            "  1.5907633  -0.34383476 -1.3195609   0.9147544  -0.5896442  -0.7366767\n",
            " -0.2108408   1.1679434   0.4293813   1.3729328   0.25223273  0.5008198\n",
            " -0.03535064 -0.47836012  0.21266921  2.4769638  -0.2734489   0.2891847\n",
            "  0.26193035  0.27140546  0.10424221  1.5299513  -0.65994495  0.4540863\n",
            "  0.08406508 -0.62546396 -0.75159025 -1.1533005  -0.32562995  0.8923292\n",
            "  0.1185151   0.4931665   0.37189943 -1.255626   -0.39329156  1.2501562\n",
            " -0.24933325 -0.95321834  0.7618496   0.9674322  -0.08899496  1.6124346 ]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [ 1.8844085   0.26155907 -0.17495197  0.91361123 -0.10704218 -0.5287218\n",
            " -0.9634074  -0.16404162  0.03572826  0.41840374 -0.07399623  1.4592811\n",
            "  0.48695335 -0.5548653  -0.05709225 -0.92454195  0.12833372  2.2001657\n",
            "  0.40398222 -0.74166214 -0.3030314   0.09293148 -0.07985841 -1.9443433\n",
            "  0.33227724  0.8256523   0.21888779 -0.2916504   0.42192942  0.7292876\n",
            "  0.20009081  1.1178632   0.27433053 -0.5611552   0.5312498  -0.948698\n",
            "  0.81973493 -0.5682527  -1.2979964   1.344887    0.08099866  1.7462792\n",
            " -1.4017252   0.6972401   0.14004904  1.047827   -1.6927366   0.17160845\n",
            "  0.687817    0.75992346 -0.6772873   0.6830205   0.17209531  1.8325372\n",
            " -0.25243968  0.8348392  -0.8417668   1.4776036  -1.3444873  -0.4091078\n",
            "  0.25952584 -0.926297    0.08443059 -0.74778134  0.6612464  -1.0684938\n",
            "  0.10954983 -0.31846604 -0.7744832   0.66486365  0.518695    0.52513975\n",
            " -1.3519921   0.22545284 -0.76880634 -0.84289235  0.33362588 -0.22829676\n",
            "  0.14913577 -0.6482012  -0.06425522  0.47452953 -0.42819673 -0.02446544\n",
            " -0.35388872  0.06645724  1.5587789  -0.15321365 -1.0424383   0.40930519\n",
            " -0.96860325 -0.5592532   0.5225469  -1.2086748  -0.571542   -0.7373039 ]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [ 1.1374708  -0.9590746  -0.2087853  -0.9746676  -0.90937656  0.61606055\n",
            " -1.014957    1.144888   -1.157334   -0.24163955 -1.1791496   0.08562639\n",
            " -0.42710036  0.5577133   0.2936328   0.47789818 -1.2022358  -0.57189405\n",
            " -1.062858   -0.34484944  1.6974971   0.35407662  0.13477021  0.0906049\n",
            " -0.12864047 -1.0549535   0.41799477 -0.23377246  1.9364651   0.45355022\n",
            "  0.64068186 -0.44832966 -0.7422728  -0.7601796  -0.17853184 -0.24783814\n",
            " -0.90338314 -0.25724554 -0.974426    0.50429916 -1.1827012   0.99488235\n",
            "  1.5455151   1.2342592   0.2657406   0.09730062 -1.2551695   0.19298804\n",
            " -0.63591594  0.16327965 -0.09438232 -0.07375789  1.6926956  -1.4352057\n",
            " -0.5522084  -0.3288837   0.72755706  0.9099815   0.02590488 -0.40952963\n",
            " -0.70864874  0.15775296 -0.15772617  0.6830623  -0.7332695  -0.29130453\n",
            "  0.6099677  -0.22555369  0.03751141  0.5023479   1.7247791   0.5102246\n",
            "  0.20997724 -0.6085861   0.2757153  -0.89916396  0.16239476 -2.4123967\n",
            "  0.10411951  0.00710003  0.13041978  0.05639115 -0.8208718  -0.2608291\n",
            " -0.11774644  0.03073207  1.648902   -0.28110772 -0.29317293  0.66678905\n",
            " -0.04422796 -0.480335    0.8013593   1.1004682  -0.5519086   0.37612593]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [-0.7412393  -0.75924647  0.5547701   0.172462   -0.08545429  0.13104354\n",
            "  1.0355792   0.70055795  0.09910606 -0.33157283 -1.1252879  -0.09259826\n",
            " -0.57104456  1.0318756  -0.05989534  0.57397467  0.06617299 -0.7227068\n",
            "  0.09195671  1.0718291  -0.75831723  0.56002104 -0.29251713 -1.2803345\n",
            " -0.06951635 -0.4710052  -0.02026364 -0.34366643 -0.7665712   0.70877796\n",
            "  0.13254943  0.11409851 -0.28705955  0.2679912   0.6755537   0.00321077\n",
            "  0.5368329  -0.2646058  -0.9216624  -1.5472112  -0.9497735   0.50938725\n",
            "  0.40250373  0.2690262  -0.10478255 -0.07045931 -0.61840737 -0.14609376\n",
            " -0.7124269   0.40312052 -0.8019999   0.19449997  0.00356853 -0.64079\n",
            "  0.8961708  -0.5347627   0.42152444 -0.38092706  0.25406265 -0.25227123\n",
            " -0.84493047  0.7971418  -0.55018175  0.03886542  1.5519265   0.3368969\n",
            " -0.466999   -0.80704445 -0.6856701  -0.46663406  0.8945781   0.9482868\n",
            "  0.9947073   0.24399593  0.18811089 -0.19140555 -0.38144737  0.08100026\n",
            "  0.293136   -1.5489024   0.09926152 -0.20878631 -0.65148914  0.21289551\n",
            " -0.06698652  0.49385473 -0.3171948  -0.7972945  -0.3419213  -0.5316941\n",
            " -1.1506073  -0.38842762  1.1151581   1.8592203  -0.22334233  1.0116861 ]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [ 0.5199622   0.21257254 -0.21301216 -0.47603622  0.25783375 -0.9749869\n",
            "  0.36250484 -0.8546686   0.709028    0.86648595  0.2889043  -0.768111\n",
            " -1.2569734  -1.4327232   1.6144778  -0.90644825 -1.7950869   1.5809036\n",
            "  1.5127933   1.319766   -0.69749814 -0.5794342  -0.42450935 -0.8283989\n",
            "  0.52580607 -0.26214778  0.5788949  -0.9647809  -0.48191172  1.1365502\n",
            "  0.2912596  -0.20588629  1.0859779   0.08508515  0.17876598 -0.10773751\n",
            "  0.4645768  -0.44268835  1.6033978  -0.99099624 -0.88028157  0.24450725\n",
            " -0.45305336 -1.171732   -0.07114539 -0.18815154  1.1827773   0.68278635\n",
            "  1.2523236  -1.2452749  -0.63681674  0.01130849  0.57234055  0.32343915\n",
            " -0.43460938 -0.02020918 -0.7885007  -1.1316612   0.57977974 -0.5900429\n",
            " -1.4168911  -1.249511    0.05177638  0.46725595  0.56477106  0.3883663\n",
            "  1.3108164  -0.10702404  0.1804241   0.5503756   1.8780737  -0.2541281\n",
            " -0.09155691 -0.35557604 -1.358618    0.64157987 -0.25393885 -0.11706573\n",
            "  0.1916557  -0.63794565  0.24892995 -0.014781   -0.00370148  0.5456412\n",
            "  0.47349143 -0.25008044 -0.29793227  1.7148315  -0.5406202   0.8574357\n",
            " -0.5011779  -0.6514914  -0.52263224  0.81065845 -0.10203366  0.04142165]\n",
            "Vector length: \n",
            " (96,)\n",
            "Word Vector Representation:\n",
            " [-7.76780009e-01  1.58006594e-01 -1.14982879e+00 -8.23847428e-02\n",
            "  2.28091717e-01  3.82549226e-01  1.26758742e+00  9.59176540e-01\n",
            " -2.10943699e-01  1.48863316e-01  5.67637384e-01  2.10180879e-03\n",
            "  2.28414029e-01  1.40946460e+00 -1.44752532e-01 -3.82433236e-01\n",
            " -9.38745975e-01 -6.13458395e-01  1.60260427e+00 -5.81712484e-01\n",
            " -6.01745307e-01  8.29485655e-01 -1.32010210e+00 -6.93155169e-01\n",
            "  2.98534632e-01  2.59162486e-02  3.95588517e-01  1.52232981e+00\n",
            " -3.76133621e-03  2.15291977e-03  2.50337183e-01  4.14645314e-01\n",
            "  7.59694815e-01  8.17201257e-01 -8.09509158e-02 -8.49782646e-01\n",
            "  1.38861597e+00  1.79786444e+00 -1.14738071e+00 -3.41659039e-01\n",
            "  2.12092578e-01  1.01988435e-01  1.50461316e-01  2.74664134e-01\n",
            " -6.38203263e-01 -6.72558784e-01 -1.83732677e+00  6.83211684e-02\n",
            " -7.31144786e-01 -5.09928763e-01 -1.88054472e-01  5.88831723e-01\n",
            "  7.13923097e-01 -2.44730145e-01 -8.41996372e-01 -1.46617770e+00\n",
            "  4.91259992e-01  3.70979190e-01  1.25233805e+00 -9.93621171e-01\n",
            " -7.49527812e-02 -1.23752820e+00 -3.66423488e-01 -9.30421531e-01\n",
            " -5.53041816e-01  6.65770173e-02  1.70222372e-01 -7.02304482e-01\n",
            " -6.62757754e-01 -2.94091195e-01  2.32114732e-01 -3.24987233e-01\n",
            "  1.79480290e+00  4.61282790e-01  1.33502078e+00 -4.08502042e-01\n",
            " -4.16939169e-01 -5.29947042e-01 -7.44758606e-01  4.18904126e-01\n",
            "  2.46230811e-02  6.65140033e-01 -1.16853452e+00 -4.57711518e-02\n",
            "  2.42180929e-01  7.00802445e-01 -4.07785289e-02 -1.36447287e+00\n",
            " -1.59245563e+00  1.75956380e+00 -9.85897362e-01  7.68313110e-02\n",
            "  3.31347203e+00  9.82865989e-02 -4.67603773e-01 -2.24320054e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 6**\n",
        "\n",
        "Find the similarity between each word of the input sentence 4. Answer the following questions:\n",
        "\n",
        "a) The words 'rotten' and 'sweet' are out of vocabulary. Identify that the statement is True or False?\n",
        "\n",
        "b) What are the similar values between 'mangoes' and 'oranges'?\n",
        "\n",
        "What are the similar values between 'sweet' and 'oranges'?\n",
        "\n",
        "Sentence 4:\n",
        "\n",
        "'Do not put rotten Mangoes and sweet oranges together.\""
      ],
      "metadata": {
        "id": "wIz47ayLONRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = str(nlp(\"Do not put rotten mangoes and sweet oranges together\"))\n",
        "\n",
        "for token in doc.split():\n",
        "    if token == \"rotten\":\n",
        "        print(\"text=\",nlp(token).text,\" | Vector=\",nlp(token).has_vector)#,\" | OOV=\",nlp(token).is_oov)\n",
        "\n",
        "    if token == \"sweet\":\n",
        "        print(\"text=\",nlp(token).text,\" | Vector=\",nlp(token).has_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN0gElmiOSV1",
        "outputId": "8f99c706-6705-431d-eff3-6e6d7bea0a93"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text= rotten  | Vector= True\n",
            "text= sweet  | Vector= True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"mangoes orange\")\n",
        "\n",
        "for token1 in doc:\n",
        "    for token2 in doc:\n",
        "        print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57JA-YFJOb4W",
        "outputId": "73992465-3baa-4d99-d07e-29e527f08e31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mangoes  |  mangoes  |  1.0\n",
            "mangoes  |  orange  |  -0.2636679708957672\n",
            "orange  |  mangoes  |  -0.2636679708957672\n",
            "orange  |  orange  |  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-d759a81825c2>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp('sweet oranges')\n",
        "\n",
        "for token1 in doc:\n",
        "    for token2 in doc:\n",
        "        print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQd_X1IzOh3G",
        "outputId": "8d662b06-50db-400f-d06b-e4afdc499485"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sweet  |  sweet  |  1.0\n",
            "sweet  |  oranges  |  0.14432832598686218\n",
            "oranges  |  sweet  |  0.14432832598686218\n",
            "oranges  |  oranges  |  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-0ded19487198>:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))\n"
          ]
        }
      ]
    }
  ]
}