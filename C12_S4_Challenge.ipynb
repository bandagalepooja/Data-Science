{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Representation and Rule-based Matching**"
      ],
      "metadata": {
        "id": "hjCw82fpzIL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Challenge Solution**"
      ],
      "metadata": {
        "id": "BFvtnd9Hzeok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyzing Gettysburg Address Text Data**\n"
      ],
      "metadata": {
        "id": "r5ST_ITg2iUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gettysburg Address is a speech that U S. President Abraham Lincoln delivered during the American Civil War at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, on the afternoon of November 19, 1863. It is one of the best-known speeches in American history.\n",
        "\n",
        "Text representation is required to make the data suitable for text analysis. Use this speech data and perform the specified tasks mentioned in the subsequent slides to represent data in the text representation.\n",
        "\n",
        "Click here to download the datafile"
      ],
      "metadata": {
        "id": "sH9xYN0Q2hi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1**"
      ],
      "metadata": {
        "id": "KtnMaaAg2n6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Import spacy, collections, English, and dictionary objects (Dict, List, Tuple).**\n",
        "\n"
      ],
      "metadata": {
        "id": "XLUhHPdz2r_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the spaCy library, which is a popular NLP library.\n",
        "import spacy\n",
        "\n",
        "# Import the collections library, which provides a variety of data structures, such as dictionaries and lists.\n",
        "import collections\n",
        "\n",
        "# Import the dictionary objects Dict, List, and Tuple, which are commonly used data structures in Python.\n",
        "from typing import Dict,List,Tuple"
      ],
      "metadata": {
        "id": "84r941s627iG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1.2 Load 'en_core_web_sm'.**\n"
      ],
      "metadata": {
        "id": "rPkf2MU12zI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a spaCy NLP pipeline.\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "NPw67o8o3272"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1.3 Read the datafile**"
      ],
      "metadata": {
        "id": "5XgrrWNJ220n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Gt0uNeJlyjvN",
        "outputId": "1474dd0f-0786-43d5-9a63-9e5b27459093"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acbe4042-67ca-47a2-a9c0-86a223d08d70\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acbe4042-67ca-47a2-a9c0-86a223d08d70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving DS3_C2_S4_GettysburgAddress_Data_Challenge.txt to DS3_C2_S4_GettysburgAddress_Data_Challenge.txt\n"
          ]
        }
      ],
      "source": [
        "# Import the files module from the google.colab package.\n",
        "from google.colab import files\n",
        "\n",
        "# Assign the variable upload to the files.upload() function, which opens a file upload dialog box.\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas liabrary\n",
        "import pandas as pd\n",
        "\n",
        "# Open the file \"DS3_C2_S4_GettysburgAddress_Data_Challenge.txt\" for reading.\n",
        "f = open(\"DS3_C2_S4_GettysburgAddress_Data_Challenge.txt\")\n",
        "\n",
        "# Read the entire contents of the file into a string variable called \"content\".\n",
        "content = f.read()\n",
        "\n",
        "# Convert the contents of the file to a string variable called \"text\"\n",
        "text = str(content)\n",
        "\n",
        "# Print text\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmwre0aA4lVT",
        "outputId": "d3032c5d-8de1-42e1-d1f2-4e5cf8eedafc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Four score and seven years ago our fathers brought forth upon this continent, a new nation,\n",
            "\n",
            " conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "Now we are engaged in a great civil war, testing whether that nation, or any nation so\n",
            "\n",
            " conceived and so dedicated, can long endure. We are met on a great battle-field of that \n",
            "\n",
            "war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
            "\n",
            "But, in a larger sense, we can not dedicate— we can not consecrate— we can not hallow— this\n",
            " ground. The brave men, living and dead, who struggled here, have consecrated it, far above\n",
            " our poor power to add or detract. The world will little note, nor long remember what we say\n",
            " here, but it can never forget what they did here. \n",
            "\n",
            "\n",
            "66666666666666666666 7777777777777\n",
            "444  222 2222  000\n",
            "\n",
            "It is for us the living, rather, to be \n",
            "dedicated here to the unfinished work which they who fought here have thus far so nobly \n",
            "advanced. \n",
            "\n",
            "\n",
            "\n",
            "It is rather for us to be here dedicated to the great task remaining before \n",
            "us—that from these honored dead we take increased devotion to that cause for which they \n",
            "gave the last full measure of devotion—that we here highly resolve that these dead shall \n",
            "not have died in vain—that this nation, under God, shall have a new birth of freedom—and \n",
            "that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "—Abraham Lincoln\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2**\n",
        "\n",
        "Represent speech texts in vector form using BOW. Supply the following for the words 'dedicated' and 'nation'\n",
        "\n",
        "a) Bow vector representation\n",
        "\n",
        "b) Dictionary values"
      ],
      "metadata": {
        "id": "BlOLtjrS4-h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Converts a text to a bag-of-words (BOW) representation.\n",
        "\n",
        "  words: A list of strings representing the words in the text.\n",
        "    dictionary: A dictionary mapping words to integers.\n",
        "\n",
        "  Returns:\n",
        "    A list of tuples, where each tuple contains a word ID and its frequency.\"\"\"\n",
        "\n",
        "def text2bow(words:List[str], dictionary: Dict[str, int]):\n",
        "\n",
        "    word_frequences = collections.defaultdict(int)\n",
        "    print(word_frequences)\n",
        "\n",
        "    for word in words:\n",
        "        if word not in dictionary:                           # check condition\n",
        "            dictionary[word] = len(dictionary)\n",
        "        word_frequences[dictionary[word]] +=1\n",
        "\n",
        "    return list(word_frequences.items())                     # return word frequency\n",
        "\n",
        "sample_text = text                                           # input text\n",
        "dictionary ={}                                               # empty dictionary\n",
        "print(text2bow(sample_text.split(),dictionary))              # calling function\n",
        "print(dictionary)                                            # print dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnBHrJ4y5zGC",
        "outputId": "1e67a769-981f-4452-c35b-de3b28b60e88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {})\n",
            "[(0, 1), (1, 1), (2, 5), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 3), (12, 1), (13, 7), (14, 2), (15, 3), (16, 2), (17, 4), (18, 1), (19, 3), (20, 8), (21, 9), (22, 1), (23, 10), (24, 1), (25, 1), (26, 3), (27, 1), (28, 1), (29, 1), (30, 8), (31, 1), (32, 3), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 2), (40, 3), (41, 1), (42, 5), (43, 2), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 5), (50, 1), (51, 5), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 5), (61, 1), (62, 3), (63, 5), (64, 2), (65, 1), (66, 1), (67, 1), (68, 1), (69, 3), (70, 3), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 5), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 2), (92, 1), (93, 1), (94, 2), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 2), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 3), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 2), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 2), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 2), (138, 2), (139, 1), (140, 2), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 3), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1), (157, 1), (158, 1), (159, 3), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1)]\n",
            "{'Four': 0, 'score': 1, 'and': 2, 'seven': 3, 'years': 4, 'ago': 5, 'our': 6, 'fathers': 7, 'brought': 8, 'forth': 9, 'upon': 10, 'this': 11, 'continent,': 12, 'a': 13, 'new': 14, 'nation,': 15, 'conceived': 16, 'in': 17, 'Liberty,': 18, 'dedicated': 19, 'to': 20, 'the': 21, 'proposition': 22, 'that': 23, 'all': 24, 'men': 25, 'are': 26, 'created': 27, 'equal.': 28, 'Now': 29, 'we': 30, 'engaged': 31, 'great': 32, 'civil': 33, 'war,': 34, 'testing': 35, 'whether': 36, 'or': 37, 'any': 38, 'nation': 39, 'so': 40, 'dedicated,': 41, 'can': 42, 'long': 43, 'endure.': 44, 'We': 45, 'met': 46, 'on': 47, 'battle-field': 48, 'of': 49, 'war.': 50, 'have': 51, 'come': 52, 'dedicate': 53, 'portion': 54, 'field,': 55, 'as': 56, 'final': 57, 'resting': 58, 'place': 59, 'for': 60, 'those': 61, 'who': 62, 'here': 63, 'gave': 64, 'their': 65, 'lives': 66, 'might': 67, 'live.': 68, 'It': 69, 'is': 70, 'altogether': 71, 'fitting': 72, 'proper': 73, 'should': 74, 'do': 75, 'this.': 76, 'But,': 77, 'larger': 78, 'sense,': 79, 'not': 80, 'dedicate—': 81, 'consecrate—': 82, 'hallow—': 83, 'ground.': 84, 'The': 85, 'brave': 86, 'men,': 87, 'living': 88, 'dead,': 89, 'struggled': 90, 'here,': 91, 'consecrated': 92, 'it,': 93, 'far': 94, 'above': 95, 'poor': 96, 'power': 97, 'add': 98, 'detract.': 99, 'world': 100, 'will': 101, 'little': 102, 'note,': 103, 'nor': 104, 'remember': 105, 'what': 106, 'say': 107, 'but': 108, 'it': 109, 'never': 110, 'forget': 111, 'they': 112, 'did': 113, 'here.': 114, '66666666666666666666': 115, '7777777777777': 116, '444': 117, '222': 118, '2222': 119, '000': 120, 'us': 121, 'living,': 122, 'rather,': 123, 'be': 124, 'unfinished': 125, 'work': 126, 'which': 127, 'fought': 128, 'thus': 129, 'nobly': 130, 'advanced.': 131, 'rather': 132, 'task': 133, 'remaining': 134, 'before': 135, 'us—that': 136, 'from': 137, 'these': 138, 'honored': 139, 'dead': 140, 'take': 141, 'increased': 142, 'devotion': 143, 'cause': 144, 'last': 145, 'full': 146, 'measure': 147, 'devotion—that': 148, 'highly': 149, 'resolve': 150, 'shall': 151, 'died': 152, 'vain—that': 153, 'under': 154, 'God,': 155, 'birth': 156, 'freedom—and': 157, 'government': 158, 'people,': 159, 'by': 160, 'perish': 161, 'earth.': 162, '—Abraham': 163, 'Lincoln': 164}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3**\n",
        "\n",
        "For the speech texts, how will you define patterns and implement token-based matching to obtain the following outcomes?\n",
        "\n",
        "a) battlefield\n",
        "\n",
        "b) battle-field\n",
        "\n",
        "Think about patterns to define.\n"
      ],
      "metadata": {
        "id": "VdRPbmTM7uyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Matcher class from the spaCy library.\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy English language model.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a Matcher object.\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern to match the word \"battlefield\".\n",
        "pattern = [{\"LOWER\": \"battle\"},{'LOWER':'field'}]\n",
        "\n",
        "# Add the pattern to the Matcher object with the ID \"battlefield\".\n",
        "matcher.add(\"battlefield\",[pattern])\n",
        "\n",
        "# Process the text using the spaCy language model.\n",
        "doc = nlp(content)\n",
        "\n",
        "# Find all matches of the \"battlefield\" pattern in the text.\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches and print the text of each match.\n",
        "for match_id,start,end in matches:\n",
        "   # Get the string ID of the matched pattern.\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "\n",
        "    # Get the span of the matched text.\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # Print the text of the matched span.\n",
        "    print(span.text)"
      ],
      "metadata": {
        "id": "pvlKlTHi9h4t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Matcher class from the spaCy library.\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the spaCy English language model.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a Matcher object.\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a pattern to match the word \"battlefield\".\n",
        "pattern = [{\"LOWER\": \"battle\"},{\"IS_PUNCT\":True},{'LOWER':'field'}]\n",
        "\n",
        "# Add the pattern to the Matcher object with the ID \"battlefield\".\n",
        "matcher.add(\"battlefield\",[pattern])\n",
        "\n",
        "# Process the text using the spaCy language model.\n",
        "doc = nlp(content)\n",
        "\n",
        "# Find all matches of the \"battlefield\" pattern in the text.\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches and print the text of each match.\n",
        "for match_id,start,end in matches:\n",
        "    # Get the string ID of the matched pattern.\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "\n",
        "    # Get the span of the matched text.\n",
        "    span = doc[start:end]\n",
        "\n",
        "    # Print the text of the matched span.\n",
        "    print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFDBKln8Dgf",
        "outputId": "a343e540-0ba4-49ac-aa41-1d21ecc2509e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "battle-field\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 4**\n",
        "\n",
        "Execute the following code to download 'en_core_web_lg' python- m spacy download en_core_web_lg. Load 'en_core_web_lg\"\n",
        "\n",
        "Do the tokens of the speech texts have a vector representation in spaCy?\n",
        "\n",
        "Are they part of the pipeline's vocabulary in spaCy or out-of-vocabulary?"
      ],
      "metadata": {
        "id": "JIxWJ-s49TlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token.text,\" | \",token.has_vector,\" | \",token.is_oov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7obKBABa94Yx",
        "outputId": "490e097e-81d2-4525-8c8b-c0e2ad21a484"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Four  |  True  |  True\n",
            "score  |  True  |  True\n",
            "and  |  True  |  True\n",
            "seven  |  True  |  True\n",
            "years  |  True  |  True\n",
            "ago  |  True  |  True\n",
            "our  |  True  |  True\n",
            "fathers  |  True  |  True\n",
            "brought  |  True  |  True\n",
            "forth  |  True  |  True\n",
            "upon  |  True  |  True\n",
            "this  |  True  |  True\n",
            "continent  |  True  |  True\n",
            ",  |  True  |  True\n",
            "a  |  True  |  True\n",
            "new  |  True  |  True\n",
            "nation  |  True  |  True\n",
            ",  |  True  |  True\n",
            "\n",
            "\n",
            "   |  True  |  True\n",
            "conceived  |  True  |  True\n",
            "in  |  True  |  True\n",
            "Liberty  |  True  |  True\n",
            ",  |  True  |  True\n",
            "and  |  True  |  True\n",
            "dedicated  |  True  |  True\n",
            "to  |  True  |  True\n",
            "the  |  True  |  True\n",
            "proposition  |  True  |  True\n",
            "that  |  True  |  True\n",
            "all  |  True  |  True\n",
            "men  |  True  |  True\n",
            "are  |  True  |  True\n",
            "created  |  True  |  True\n",
            "equal  |  True  |  True\n",
            ".  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "Now  |  True  |  True\n",
            "we  |  True  |  True\n",
            "are  |  True  |  True\n",
            "engaged  |  True  |  True\n",
            "in  |  True  |  True\n",
            "a  |  True  |  True\n",
            "great  |  True  |  True\n",
            "civil  |  True  |  True\n",
            "war  |  True  |  True\n",
            ",  |  True  |  True\n",
            "testing  |  True  |  True\n",
            "whether  |  True  |  True\n",
            "that  |  True  |  True\n",
            "nation  |  True  |  True\n",
            ",  |  True  |  True\n",
            "or  |  True  |  True\n",
            "any  |  True  |  True\n",
            "nation  |  True  |  True\n",
            "so  |  True  |  True\n",
            "\n",
            "\n",
            "   |  True  |  True\n",
            "conceived  |  True  |  True\n",
            "and  |  True  |  True\n",
            "so  |  True  |  True\n",
            "dedicated  |  True  |  True\n",
            ",  |  True  |  True\n",
            "can  |  True  |  True\n",
            "long  |  True  |  True\n",
            "endure  |  True  |  True\n",
            ".  |  True  |  True\n",
            "We  |  True  |  True\n",
            "are  |  True  |  True\n",
            "met  |  True  |  True\n",
            "on  |  True  |  True\n",
            "a  |  True  |  True\n",
            "great  |  True  |  True\n",
            "battle  |  True  |  True\n",
            "-  |  True  |  True\n",
            "field  |  True  |  True\n",
            "of  |  True  |  True\n",
            "that  |  True  |  True\n",
            "\n",
            "\n",
            "  |  True  |  True\n",
            "war  |  True  |  True\n",
            ".  |  True  |  True\n",
            "We  |  True  |  True\n",
            "have  |  True  |  True\n",
            "come  |  True  |  True\n",
            "to  |  True  |  True\n",
            "dedicate  |  True  |  True\n",
            "a  |  True  |  True\n",
            "portion  |  True  |  True\n",
            "of  |  True  |  True\n",
            "that  |  True  |  True\n",
            "field  |  True  |  True\n",
            ",  |  True  |  True\n",
            "as  |  True  |  True\n",
            "a  |  True  |  True\n",
            "final  |  True  |  True\n",
            "resting  |  True  |  True\n",
            "place  |  True  |  True\n",
            "for  |  True  |  True\n",
            "those  |  True  |  True\n",
            "who  |  True  |  True\n",
            "here  |  True  |  True\n",
            "gave  |  True  |  True\n",
            "their  |  True  |  True\n",
            "lives  |  True  |  True\n",
            "that  |  True  |  True\n",
            "that  |  True  |  True\n",
            "nation  |  True  |  True\n",
            "might  |  True  |  True\n",
            "live  |  True  |  True\n",
            ".  |  True  |  True\n",
            "It  |  True  |  True\n",
            "is  |  True  |  True\n",
            "altogether  |  True  |  True\n",
            "fitting  |  True  |  True\n",
            "and  |  True  |  True\n",
            "proper  |  True  |  True\n",
            "that  |  True  |  True\n",
            "we  |  True  |  True\n",
            "should  |  True  |  True\n",
            "do  |  True  |  True\n",
            "this  |  True  |  True\n",
            ".  |  True  |  True\n",
            "\n",
            "\n",
            "  |  True  |  True\n",
            "But  |  True  |  True\n",
            ",  |  True  |  True\n",
            "in  |  True  |  True\n",
            "a  |  True  |  True\n",
            "larger  |  True  |  True\n",
            "sense  |  True  |  True\n",
            ",  |  True  |  True\n",
            "we  |  True  |  True\n",
            "can  |  True  |  True\n",
            "not  |  True  |  True\n",
            "dedicate  |  True  |  True\n",
            "—  |  True  |  True\n",
            "we  |  True  |  True\n",
            "can  |  True  |  True\n",
            "not  |  True  |  True\n",
            "consecrate  |  True  |  True\n",
            "—  |  True  |  True\n",
            "we  |  True  |  True\n",
            "can  |  True  |  True\n",
            "not  |  True  |  True\n",
            "hallow  |  True  |  True\n",
            "—  |  True  |  True\n",
            "this  |  True  |  True\n",
            "\n",
            "   |  True  |  True\n",
            "ground  |  True  |  True\n",
            ".  |  True  |  True\n",
            "The  |  True  |  True\n",
            "brave  |  True  |  True\n",
            "men  |  True  |  True\n",
            ",  |  True  |  True\n",
            "living  |  True  |  True\n",
            "and  |  True  |  True\n",
            "dead  |  True  |  True\n",
            ",  |  True  |  True\n",
            "who  |  True  |  True\n",
            "struggled  |  True  |  True\n",
            "here  |  True  |  True\n",
            ",  |  True  |  True\n",
            "have  |  True  |  True\n",
            "consecrated  |  True  |  True\n",
            "it  |  True  |  True\n",
            ",  |  True  |  True\n",
            "far  |  True  |  True\n",
            "above  |  True  |  True\n",
            "\n",
            "   |  True  |  True\n",
            "our  |  True  |  True\n",
            "poor  |  True  |  True\n",
            "power  |  True  |  True\n",
            "to  |  True  |  True\n",
            "add  |  True  |  True\n",
            "or  |  True  |  True\n",
            "detract  |  True  |  True\n",
            ".  |  True  |  True\n",
            "The  |  True  |  True\n",
            "world  |  True  |  True\n",
            "will  |  True  |  True\n",
            "little  |  True  |  True\n",
            "note  |  True  |  True\n",
            ",  |  True  |  True\n",
            "nor  |  True  |  True\n",
            "long  |  True  |  True\n",
            "remember  |  True  |  True\n",
            "what  |  True  |  True\n",
            "we  |  True  |  True\n",
            "say  |  True  |  True\n",
            "\n",
            "   |  True  |  True\n",
            "here  |  True  |  True\n",
            ",  |  True  |  True\n",
            "but  |  True  |  True\n",
            "it  |  True  |  True\n",
            "can  |  True  |  True\n",
            "never  |  True  |  True\n",
            "forget  |  True  |  True\n",
            "what  |  True  |  True\n",
            "they  |  True  |  True\n",
            "did  |  True  |  True\n",
            "here  |  True  |  True\n",
            ".  |  True  |  True\n",
            "\n",
            "\n",
            "\n",
            "  |  True  |  True\n",
            "66666666666666666666  |  True  |  True\n",
            "7777777777777  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "444  |  True  |  True\n",
            "   |  True  |  True\n",
            "222  |  True  |  True\n",
            "2222  |  True  |  True\n",
            "   |  True  |  True\n",
            "000  |  True  |  True\n",
            "\n",
            "\n",
            "  |  True  |  True\n",
            "It  |  True  |  True\n",
            "is  |  True  |  True\n",
            "for  |  True  |  True\n",
            "us  |  True  |  True\n",
            "the  |  True  |  True\n",
            "living  |  True  |  True\n",
            ",  |  True  |  True\n",
            "rather  |  True  |  True\n",
            ",  |  True  |  True\n",
            "to  |  True  |  True\n",
            "be  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "dedicated  |  True  |  True\n",
            "here  |  True  |  True\n",
            "to  |  True  |  True\n",
            "the  |  True  |  True\n",
            "unfinished  |  True  |  True\n",
            "work  |  True  |  True\n",
            "which  |  True  |  True\n",
            "they  |  True  |  True\n",
            "who  |  True  |  True\n",
            "fought  |  True  |  True\n",
            "here  |  True  |  True\n",
            "have  |  True  |  True\n",
            "thus  |  True  |  True\n",
            "far  |  True  |  True\n",
            "so  |  True  |  True\n",
            "nobly  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "advanced  |  True  |  True\n",
            ".  |  True  |  True\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  |  True  |  True\n",
            "It  |  True  |  True\n",
            "is  |  True  |  True\n",
            "rather  |  True  |  True\n",
            "for  |  True  |  True\n",
            "us  |  True  |  True\n",
            "to  |  True  |  True\n",
            "be  |  True  |  True\n",
            "here  |  True  |  True\n",
            "dedicated  |  True  |  True\n",
            "to  |  True  |  True\n",
            "the  |  True  |  True\n",
            "great  |  True  |  True\n",
            "task  |  True  |  True\n",
            "remaining  |  True  |  True\n",
            "before  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "us  |  True  |  True\n",
            "—  |  True  |  True\n",
            "that  |  True  |  True\n",
            "from  |  True  |  True\n",
            "these  |  True  |  True\n",
            "honored  |  True  |  True\n",
            "dead  |  True  |  True\n",
            "we  |  True  |  True\n",
            "take  |  True  |  True\n",
            "increased  |  True  |  True\n",
            "devotion  |  True  |  True\n",
            "to  |  True  |  True\n",
            "that  |  True  |  True\n",
            "cause  |  True  |  True\n",
            "for  |  True  |  True\n",
            "which  |  True  |  True\n",
            "they  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "gave  |  True  |  True\n",
            "the  |  True  |  True\n",
            "last  |  True  |  True\n",
            "full  |  True  |  True\n",
            "measure  |  True  |  True\n",
            "of  |  True  |  True\n",
            "devotion  |  True  |  True\n",
            "—  |  True  |  True\n",
            "that  |  True  |  True\n",
            "we  |  True  |  True\n",
            "here  |  True  |  True\n",
            "highly  |  True  |  True\n",
            "resolve  |  True  |  True\n",
            "that  |  True  |  True\n",
            "these  |  True  |  True\n",
            "dead  |  True  |  True\n",
            "shall  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "not  |  True  |  True\n",
            "have  |  True  |  True\n",
            "died  |  True  |  True\n",
            "in  |  True  |  True\n",
            "vain  |  True  |  True\n",
            "—  |  True  |  True\n",
            "that  |  True  |  True\n",
            "this  |  True  |  True\n",
            "nation  |  True  |  True\n",
            ",  |  True  |  True\n",
            "under  |  True  |  True\n",
            "God  |  True  |  True\n",
            ",  |  True  |  True\n",
            "shall  |  True  |  True\n",
            "have  |  True  |  True\n",
            "a  |  True  |  True\n",
            "new  |  True  |  True\n",
            "birth  |  True  |  True\n",
            "of  |  True  |  True\n",
            "freedom  |  True  |  True\n",
            "—  |  True  |  True\n",
            "and  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "that  |  True  |  True\n",
            "government  |  True  |  True\n",
            "of  |  True  |  True\n",
            "the  |  True  |  True\n",
            "people  |  True  |  True\n",
            ",  |  True  |  True\n",
            "by  |  True  |  True\n",
            "the  |  True  |  True\n",
            "people  |  True  |  True\n",
            ",  |  True  |  True\n",
            "for  |  True  |  True\n",
            "the  |  True  |  True\n",
            "people  |  True  |  True\n",
            ",  |  True  |  True\n",
            "shall  |  True  |  True\n",
            "not  |  True  |  True\n",
            "perish  |  True  |  True\n",
            "from  |  True  |  True\n",
            "the  |  True  |  True\n",
            "earth  |  True  |  True\n",
            ".  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n",
            "—  |  True  |  True\n",
            "Abraham  |  True  |  True\n",
            "Lincoln  |  True  |  True\n",
            "\n",
            "  |  True  |  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 5**\n",
        "\n",
        "For the speech texts, the phrases 'long endure' and 'resting place should be matched using defined patterns ['long endure', 'resting place'].\n",
        "\n",
        "How will you set the attributes to achieve this?"
      ],
      "metadata": {
        "id": "6gtCYh0G-qI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy PhraseMatcher to find exact instances of phrases in a text.\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Create a new PhraseMatcher object.\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "\n",
        "# Create a list of phrases to match.\n",
        "terms = [\"long endure\",\"resting place\"]\n",
        "\n",
        "# Create a list of spaCy Doc objects from the list of phrases.\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "\n",
        "# Add the patterns to the PhraseMatcher object.\n",
        "matcher.add(\"\",patterns)\n",
        "\n",
        "# Load the text to search into a spaCy Doc object.\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the matches found by the PhraseMatcher object.\n",
        "for match_id,start,end in matcher(doc):\n",
        "    print(doc[start:end])         # Print the matched text."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv3hcerA-pb5",
        "outputId": "0bc8f61b-ed24-4a7d-faad-ab1c63a15d5b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "long endure\n",
            "resting place\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task - 6**\n",
        "\n",
        "Represent speech text in the vector form using word vector representation.\n",
        "\n",
        "What is the total length of output vectors?"
      ],
      "metadata": {
        "id": "WKvl6hYAAT5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# length of vector\n",
        "\n",
        "doc.vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQYx8wn_Aaao",
        "outputId": "52ce5455-102d-4a01-fb1a-ceb1f5b316c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector numbers\n",
        "\n",
        "doc.vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfT9UdHhAdP4",
        "outputId": "ea78a964-e218-4e9d-dbc0-440015cea2e4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.11224575, -0.2755308 , -0.0648795 , -0.03700626, -0.04325729,\n",
              "        0.15692633,  0.05856009,  0.05960033,  0.07173745,  0.17168066,\n",
              "       -0.13233267,  0.22620872, -0.26355806,  0.03330753, -0.07637579,\n",
              "       -0.17697139,  0.11305751,  0.11847576, -0.01329103, -0.07913036,\n",
              "        0.06090962,  0.30062747,  0.05478362, -0.27772897, -0.03164646,\n",
              "       -0.03291905,  0.22353782,  0.12076934,  0.1242673 ,  0.05988366,\n",
              "        0.00327474,  0.01875209,  0.42053464, -0.08467228,  0.229732  ,\n",
              "       -0.22413518,  0.24621564, -0.1894398 , -0.04794111, -0.09005581,\n",
              "       -0.31812707,  0.11526684, -0.06694183, -0.07767091,  0.18534514,\n",
              "        0.07556131, -0.03481111,  0.15802333,  0.07112998, -0.0223304 ,\n",
              "       -0.35075742, -0.00609015, -0.06427025,  0.07000443,  0.11222431,\n",
              "        0.09198102, -0.0290524 , -0.05030384,  0.01403959, -0.11956887,\n",
              "        0.1607308 , -0.10655373, -0.04611418,  0.09352808,  0.11231744,\n",
              "        0.00842134,  0.02193254, -0.3816418 ,  0.1670724 ,  0.2383513 ,\n",
              "       -0.23255111,  0.09418701, -0.18529828, -0.10564409,  0.11170865,\n",
              "       -0.09328435, -0.0198512 , -0.1918921 ,  0.0296195 , -0.08993765,\n",
              "       -0.19513161, -0.02309162, -0.22838639,  0.06040702,  0.12865588,\n",
              "        0.3162639 ,  0.02514742,  0.13380381, -0.2405647 ,  0.22479825,\n",
              "        0.05373098, -0.09525396,  0.24476726,  0.27173066, -0.13112557,\n",
              "       -0.03410233], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 7**\n",
        "\n",
        "Find the similarity between each word of text that exists in the speech.\n"
      ],
      "metadata": {
        "id": "ZT8PFIxz9HrV"
      }
    }
  ]
}